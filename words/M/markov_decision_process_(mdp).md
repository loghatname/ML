---
layout: word
word: Markov Decision Process (MDP)
translation: 'فرایند تصمیم گیری مارکوف (MDP)'
---

[](/S/state/)یک چارچوب ریاضی است برای مدل‌سازی تصمیم‌گیری در شرایطی که نتایج تا حدودی تصادفی و تا حدودی تحت کنترل یک تصمیم‌گیر است. MDPs برای مطالعه طیف گسترده‌ای از مسائل [بهینه سازی](https://fa.wikipedia.org/wiki/%D8%A8%D9%87%DB%8C%D9%86%D9%87%E2%80%8C%D8%B3%D8%A7%D8%B2%DB%8C 'بهینه‌سازی') که از طریق [برنامه‌نویسی پویا](https://fa.wikipedia.org/wiki/%D8%A8%D8%B1%D9%86%D8%A7%D9%85%D9%87%E2%80%8C%D8%B1%DB%8C%D8%B2%DB%8C_%D9%BE%D9%88%DB%8C%D8%A7 'برنامه‌ریزی پویا') و [یادگیری تقویتی](</R/reinforcement_learning_(rl)>) حل می‌شوند مفید است.

تصویر زیر یک نمونه ساده از MDP است:

![](/assets/img/20060904224736-markov_decision_process_example.png)

این نمونه دارای ۳ [حالت](/S/state) (دایره های سبز رنگ) و ۲ [عمل](/A/action) (a0 , a1) و ۲ [پاداش](/R/reward) ( خط های نارنجی رنگ) است.
